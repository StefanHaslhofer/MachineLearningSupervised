{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Assignment 6: Logistic Regression</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Copyright and Fair Use</h2>\n",
    "\n",
    "This material, no matter whether in printed or electronic form,\n",
    "may be used for personal and non-commercial educational use\n",
    "only. Any reproduction of this material, no matter whether as a\n",
    "whole or in parts, no matter whether in printed or in electronic\n",
    "form, requires explicit prior acceptance of the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h2 style=\"color:rgb(0,120,170)\">Automatic Testing Guidelines</h2>\n",
    "\n",
    "Automatic unittesting requires you to submit a notebook which contains strictly defined objects.\n",
    "Strictness of definition consists of unified shapes, dtypes, variable names and more.\n",
    "\n",
    "Within the notebook, we provide detailed instruction which you should follow in order to maximise your final grade.\n",
    "\n",
    "**Name your notebook properly**, follow the pattern in the template name:\n",
    "\n",
    "**Assignment_N_NameSurname_matrnumber**\n",
    "<ol>\n",
    "    <li>N - number of assignment</li>\n",
    "    <li>NameSurname - your full name where every part of the name starts with a capital letter, no spaces</li>\n",
    "    <li>matrnumber - you student number on ID card (without k, potenitially with a leading zero)</li>\n",
    "</ol>\n",
    "\n",
    "Don't add any cells but use the ones provided by us. You may notice that all cells are tagged such that the unittest routine can recognise them. Before you sumbit your solution, make sure every cell has its (correct) tag!\n",
    "\n",
    "You can implement helper functions where needed unless you put them in the same cell they are actually called. Always make sure that implemented functions have the correct output and given variables contain the correct data type. In the descriptions for every function you can find information on what datatype an output should have and you should stick to that in order to minimize conflicts with the unittest. Don't import any other packages than listed in the cell with the \"imports\" tag.\n",
    "\n",
    "Questions are usually multiple choice (except the task description says otherwise) and can be answered by changing the given variables to either \"True\" or \"False\". \"None\" is counted as a wrong answer in any case!\n",
    "\n",
    "**Note:** Never use variables you defined in another cell in your functions directly; always pass them to the function as a parameter. In the unitest, they won't be available either. If you want to make sure that everything is executable for the unittest, try executing cells/functions individually (instead of running the whole notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "imports"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "# set the seed for reproducability to 44\n",
    "RSEED = 44\n",
    "np.random.seed(RSEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"color:rgb(210,90,80)\">Task 1:</h2>\n",
    "\n",
    "The goal of this exercise is to implement logistic regression from scratch using only numpy - do not import any new packages! \n",
    "\n",
    "Start with the following tasks:\n",
    "\n",
    "1. Implement the formula for the gradient computed in the lecture. In particular you should implement a function \n",
    "`logistic_gradient(w, x, y)` that takes a parameter vector\n",
    "$\\mathbf{w}$, a data matrix $\\mathbf{X}$ and a label vector\n",
    "$\\mathbf{y}$ and returns the gradient $\\frac{\\partial L}{\\partial\n",
    "\\mathbf{w}}$, where $L$ is the negative log-likelihood for the Bernoulli distribution, i.e. the cross-entropy loss.\n",
    "\n",
    "2. Implement a function `cost(w, x, y)`, that takes the same parameters but returns the cross-entropy loss.\n",
    "\n",
    "3. Test whether the gradient calculated by `logistic_gradient(w, x, y)` is correct via Gradient Checking. To do so, implement\n",
    "a function `numerical_gradient(w, x, y, eps_list)` that takes the same parameters\n",
    "as `logistic_gradient` and an additional parameter `eps_list` , which calculates the gradient numerically via the central difference quotient, taking a list of values of $\\epsilon$ as input and returns a list of the same length as `eps_list`, containing the computed gradients for each $\\epsilon$.\n",
    "4. Implement the function `generate_random(nr_samples, nr_features)` that generates a random data matrix consisting of 5 data points with 10 features drawn from a standard normal distribution as well as corresponding random binary labels and a random weight vector, whose entries again stem from the standard normal distribution.  Hint: to generate the distributions use `np.random.normal` and `np.random.randint`.\n",
    "\n",
    "5. Implement the function `comparison(grad_a,grad_n)` that takes the analytical and the numerical gradient, as inputs and checks whether or not the two vectors deviate more than $\\varepsilon_\\textrm{tol} = 10^{-7}$ (absolute tolerance) from each other and answer the questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Code 1.1 (5 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "code1.1"
    ]
   },
   "outputs": [],
   "source": [
    "def logistic_gradient(w:np.ndarray, x:np.ndarray, y:np.ndarray)->np.ndarray:\n",
    "    \"\"\"Function that computes the logistic gradient via the cross-entropy loss.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w : np.ndarray\n",
    "        weights \n",
    "    x : np.ndarray\n",
    "        data matrix\n",
    "    y : np.ndarray\n",
    "        data labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        gradient vector\n",
    "    \"\"\"\n",
    "    gradient = None\n",
    "    #Your code goes here ↓↓↓\n",
    "\n",
    "    return gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Code 1.2 (5 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "code1.2"
    ]
   },
   "outputs": [],
   "source": [
    "def cost(w:np.ndarray, x:np.ndarray, y:np.ndarray)->float:\n",
    "    \"\"\"Function that computes the cross-entropy loss\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    w : np.ndarray\n",
    "        weights\n",
    "    x : np.ndarray\n",
    "        data matrix\n",
    "    y : np.ndarray\n",
    "        data labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        cross-entropy loss\n",
    "    \"\"\"\n",
    "    loss = None\n",
    "    #Your code goes here ↓↓↓\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Code 1.3 (10 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": [
     "code1.3"
    ]
   },
   "outputs": [],
   "source": [
    "def numerical_gradient(w:np.ndarray, x:np.ndarray, y:np.ndarray, eps_list:list, cost_function: callable)-> list:\n",
    "    \"\"\"Function that computes the numerical gradient for each epsilon in eps_list.\n",
    "    Hint: Use the previously implemented cost function, it is given as input to this function, \n",
    "    make sure to call it with the correct name (cost_function(...), not cost(...))!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w : np.ndarray\n",
    "        weights\n",
    "    x : np.ndarray\n",
    "        data matrix\n",
    "    y : np.ndarray\n",
    "        data labels\n",
    "    eps : list\n",
    "        list of floats; the epsilon values for difference quotient calculation\n",
    "    cost_function: callable\n",
    "        function that calculates the cross-entropy loss, implemented by you\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        list of same length as eps_list containing the np.ndarrays from the computed gradients for each epsilon in eps_list\n",
    "    \"\"\"\n",
    "    dw_list = []\n",
    "    \n",
    "    #Your code goes here ↓↓↓\n",
    "\n",
    "    return dw_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Code 1.4 (10 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "code1.4"
    ]
   },
   "outputs": [],
   "source": [
    "def generate_random(nr_samples:int, nr_features:int, seed = RSEED)-> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Function that generates a random matrix X and the random vectors y and weights according to input specifications.\n",
    "    Hint: to generate the distributions use numpy's np.random.<...> functions.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nr_samples : int,\n",
    "        number of samples to generate\n",
    "    nr_features : int,\n",
    "        number of features of each sample\n",
    "    seed: int, optional\n",
    "        seed for np.random, dont change it!\n",
    "    Returns\n",
    "    -------\n",
    "    tuple(np.ndarray,np.ndarray,np.ndarray)\n",
    "        returns randomly generated data matrices X,y and w.\n",
    "    \"\"\"\n",
    "    # don't change the seed!\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    X_random = None\n",
    "    y_random = None\n",
    "    w_random = None\n",
    "\n",
    "    #Your code goes here ↓↓↓\n",
    "\n",
    "\n",
    "    return (X_random, y_random, w_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h3 style=\"color:rgb(210,90,80)\">Code and Questions 1.5 (4+6 points):</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "code1.5"
    ]
   },
   "outputs": [],
   "source": [
    "def comparison(grad_a:np.ndarray,grad_n:np.ndarray) -> bool:\n",
    "    \"\"\"Function that compares two arrays, in our case the numerical and analytical gradients.\n",
    "    Hint: use absolute tolerance, with an error tolerance of 1e-7.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    grad_a : np.ndarray\n",
    "        the analytical gradient\n",
    "    grad_n : np.ndarray\n",
    "        the numberical gradient\n",
    "  \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True, if arrays are close, according to our specifications, False if not. \n",
    "    \"\"\"\n",
    "    close = None\n",
    "    \n",
    "    #Your code goes here ↓↓↓    \n",
    "\n",
    "    return close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exec"
    ]
   },
   "outputs": [],
   "source": [
    "#Nothing to do here, if you did everything correctly, you can just run this code and should see the correct results\n",
    "\n",
    "n = 5       #number of samples\n",
    "d = 10      #number of features\n",
    "eps_list = [1e-1,1e-4,1e-11]     # epsilon values to test\n",
    "X_random, y_random, w_random = generate_random(n,10,RSEED)\n",
    "analytical_gradient = logistic_gradient(w_random,X_random,y_random)\n",
    "num_gradients = numerical_gradient(w_random,X_random,y_random,eps_list,cost)\n",
    "comparison_results=[]\n",
    "for grad in num_gradients:\n",
    "    comparison_results.append(comparison(analytical_gradient, grad))\n",
    "# Check outputs\n",
    "assert len(comparison_results) == len(eps_list), \"List with comparison results should be the same length as there are epsilon values.\"\n",
    "assert isinstance(comparison_results[0],bool), f\"Comparison results should be list of booleans.\"\n",
    "print(\"Your randomly generated data:\\n\")\n",
    "print(\"X =\",X_random,\"\\n\")\n",
    "print(\"y =\",y_random,\"\\n\")\n",
    "print(\"w = \",w_random,\"\\n\")\n",
    "print(\"Logistic gradient:\\n\",analytical_gradient,\"\\n\")\n",
    "for i,res in enumerate(comparison_results):\n",
    "    eps_ = eps_list[i]\n",
    "    print(f\"Numerical gradient {i} with epsilon = {eps_}:\\n\", num_gradients[i], \"\\n\")\n",
    "    print(\"    Vectors within absolute tolerance of 10^-7: \",res, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Fill in your results from the comparison of the computed gradients for each of the 3 epsilons and answer the questions below:***\n",
    "\n",
    "\n",
    "Q1: Following the results from your comparison function, if at all, why do you think is the right choice of $\\epsilon$ crucial, for computing adequate approximations with the numerical gradient function?\n",
    "\n",
    "a15_) The choice does not matter, as long as epsilon is in (0,1) the function will give a satisfying solution, according to our tolerance criterion.<br>\n",
    "b15_) Very large values for $\\epsilon$, e.g. $\\epsilon=0.1$, lead to a divergence of the gradient as the denominator approaches zero. <br>\n",
    "c15_) Very small values for $\\epsilon$, e.g. $\\epsilon \\leq \\text{1e-11}$, can result in calculation errors, this could be due to issues with numerical precision, as both values in the numerator as well as in the denominator are very small.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "q1"
    ]
   },
   "outputs": [],
   "source": [
    "# examples for you\n",
    "example_of_true_variable = True\n",
    "example_of_false_variable = False\n",
    "\n",
    "# your answers go here ↓↓↓\n",
    "# comparison results for eps_list(eps_0_,eps_1_,eps_2_)\n",
    "\n",
    "eps_0_ = None\n",
    "eps_1_ = None\n",
    "eps_2_ = None\n",
    "\n",
    "# Q1\n",
    "\n",
    "a15_ = None\n",
    "b15_ = None\n",
    "c15_ = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Did you notice that we left out the bias term in our implementation of the logistic regression? (In the lecture Unit 5, Slide 45/47 shows the logistic unit with bias.) The bias $b$ represents the log-odds of the probability that the dependent variable takes on the value of 1 when all independent variables are set to zero.\n",
    "\n",
    "Why was it okay to not use a bias for our data? \n",
    "\n",
    "d15_) The bias term cancels out when calculating the derivative of the loss-function, because it does not depend on $\\mathbf{X}$.<br>\n",
    "e15_) The bias is only relevant when all independent variables are exactly 0, which never actually happens in real data.<br>\n",
    "f15_) The data follows a standard normal distribution, hence a bias of 0 leads to the correct predictions.<br>\n",
    "\n",
    "To answer the question, assign \"True\" or \"False\" boolean values to variables in the next cell. A non-correctly answered question yields 0 points and no answer (i.e. answer “None”) also gives 0 points for the question. There can be 1, more than 1, or no correct answer(s).<br>\n",
    "<b>Note:</b> Do not reuse these variable names. They are used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "q2"
    ]
   },
   "outputs": [],
   "source": [
    "# examples for you\n",
    "example_of_true_variable = True\n",
    "example_of_false_variable = False\n",
    "\n",
    "# your answers go here ↓↓↓\n",
    "# Q2\n",
    "\n",
    "d15_ = None\n",
    "e15_ = None\n",
    "f15_ = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "Next we intend to apply logistic regression on a real data set.\n",
    "\n",
    "6. Implement a function `fitLogRegModel(...)` that uses Logistic Regression with Gradient Descent to train classifiers on the training set. Use randomly initialized weights, drawn from a uniform distribution between $-1$ and $1$, a default learning rate $\\eta$ (eta) of $10^{-4}$ and a maximum number of iterations of $1e5$. Furthermore the algorithm should stop either if the difference between the loss of the last iteration step and the current loss is less than the `stopping_criterion=1e-5` or the maximum of allowed iterations (`max_iter=1e5`) is reached. Store all the losses in a list to have some insights in the learning procedure later on. Also print the losses in $1000$ step intervals (also at step 0!). The function should return the model weights and the list containing all the losses.\n",
    "7. Furthermore, implement a function `predictLogReg(w, x)` that returns the prediction for the given parameter vector $\\mathbf{w}$ and feature vector $\\mathbf{x}$.\n",
    "\n",
    "Hint: for intialization use `np.random.uniform`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h3 style=\"color:rgb(208,90,80)\">Code 1.6 (20 points)</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code1.6"
    ]
   },
   "outputs": [],
   "source": [
    "def fitLogRegModel(x_train:np.ndarray, y_train:np.ndarray, cost_function: callable, log_grad_function:callable, \n",
    "                   eta=1e-4, stopping_criterion = 1e-5, max_iter=1e5,seed=RSEED)->Tuple[np.ndarray,list]:\n",
    "    \"\"\"Function that fits a logistic regression model to the given data. \n",
    "    Print's the loss every 1000 steps (also in the beginning at step 0).\n",
    "    Training stops eather if the change of the current loss to the loss of the previous iteration is smaller than the stopping criterion,\n",
    "    or max_iter is reached. Don't change any of them!\n",
    "    All losses including the loss before training are stored in a list and returned.\n",
    "    Hint: make sure to initialize the weights-array from a random uniform distribution with numpy \n",
    "    and with the correct dimensions according to x_train.\n",
    "    Again: Use the function names specified in the input (log_grad_function(...), not logistic_gradient(...))!\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_train : np.ndarray\n",
    "        training data\n",
    "    y_train : np.ndarray\n",
    "        training labels\n",
    "    cost_function: callable\n",
    "        function that calculates the cross-entropy loss, implemented by you\n",
    "    log_grad_function: callable\n",
    "        function that calculates the logistic gradient, implemented by you\n",
    "    eta: float\n",
    "        learning rate and stopping criterion\n",
    "    max_iter : int, optional\n",
    "        max iteratioan at which training should stop, by default 100000, don't change it.\n",
    "    seed : _type_, optional\n",
    "        seed for numpy, by default RSEED\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray,list]\n",
    "        w: array of the final computed weights\n",
    "        losses: list of floats holding all the losses from training (including the loss before the training)\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    # initliaze weights and list of losses\n",
    "    w = None\n",
    "    losses = []\n",
    "    max_iter = int(max_iter)\n",
    "\n",
    "    # your code go here ↓↓↓\n",
    "\n",
    "    \n",
    "    return w,losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h3 style=\"color:rgb(208,90,80)\">Code and Questions 1.7 (10 points)</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code1.7"
    ]
   },
   "outputs": [],
   "source": [
    "def predictLogReg(w:np.ndarray, x:np.ndarray)-> np.ndarray:\n",
    "    \"\"\"Function that calculates the prediction for one or more new and unseen samples, from the previously trained weights. \n",
    "    Do not use any packages for this task except numpy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    w : np.ndarray\n",
    "        Array of trained weights\n",
    "    x : np.ndarray\n",
    "        point(s) to make predictions for\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        1D array of calculated predictions, size = number of points in x, floats between 0 and 1\n",
    "    \"\"\"\n",
    "    prediction = None\n",
    "\n",
    "    # your code go here ↓↓↓\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fit the logistic regression model from above to the training data and print the parameters for the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exec"
    ]
   },
   "outputs": [],
   "source": [
    "#nothing to do here, just run the cell\n",
    "\n",
    "# Read data, split into X(features) and y(labels)\n",
    "Z = np.genfromtxt('DataSet_LR_a.csv', delimiter=',',skip_header=1)\n",
    "X, y = Z[:,:-1], Z[:,-1]\n",
    "#prepend ones for intercept\n",
    "X = np.hstack((np.ones((X.shape[0],1)),X))   \n",
    "\n",
    "# Plot data distribution\n",
    "color= ['red' if elem==1 else 'blue' for elem in y ]\n",
    "plt.scatter(X[:,-2], X[:,-1], c=color)\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.title('Complete dataset')\n",
    "# Split into test and training set\n",
    "X_train=X[:int(X.shape[0]/2)]\n",
    "X_test=X[int(X.shape[0]/2):]\n",
    "y_train=y[:int(len(y)/2)]\n",
    "y_test=y[int(len(y)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "playground"
    ]
   },
   "outputs": [],
   "source": [
    "# try out different values for eta and answer the questions\n",
    "pred_train = []\n",
    "pred_test = []\n",
    "# specify your etas here:\n",
    "eta_list = [1e-4]\n",
    "for lr in eta_list:\n",
    "    w_learned,losses=fitLogRegModel(X_train, y_train,cost,logistic_gradient,eta=lr)\n",
    "    pred_train.append(predictLogReg(w_learned, X_train)) #as a check\n",
    "    pred_test.append(predictLogReg(w_learned, X_test))\n",
    "    print(\"The learnt weights are: w =\",w_learned,\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Try out different values of eta in the cell above and answer the question below:***\n",
    "\n",
    "\n",
    "Q3: Following your experiments with the the learning rate (eta), which of the following statements are correct?\n",
    "\n",
    "a17_) Learning rates > 0.5 lead to fast convergence and reasonably good predictions on the test data.<br>\n",
    "b17_) For learning rates smaller than 1e-6 the algorithm does not converge before max_iter is reached. <br>\n",
    "c17_) When inspecting the plot for the default learning rate 1e-4, we see that also the outliers are classified correctly.<br>\n",
    "d17_) No matter what learning rate we choose from (0,1), if the algorithm converges, the resulting weights are always the same (within a small tolerance of $\\sim|0.1|$)<br>\n",
    "e17_) If we trained the classifier for a very long time, with the optimal learning rate, the resulting model would separate the training data perfectly (accuracy=1), but it would perform much worse on the test data (overfitting).<br>\n",
    "\n",
    "***For some questions you may want to plot and inspect the classifier results with the plotting function below the questions.***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "q3"
    ]
   },
   "outputs": [],
   "source": [
    "# examples for you\n",
    "example_of_true_variable = True\n",
    "example_of_false_variable = False\n",
    "\n",
    "# your answers go here ↓↓↓\n",
    "# Q3\n",
    "\n",
    "a17_ = None\n",
    "b17_ = None\n",
    "c17_ = None\n",
    "d17_ = None\n",
    "e17_ = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exec"
    ]
   },
   "outputs": [],
   "source": [
    "# Nothing to do here\n",
    "# Plot training and test dataset\n",
    "# Plot predictions for training and test dataset\n",
    "for i,_ in enumerate(pred_train):\n",
    "    fig = plt.figure(figsize = (12,10))\n",
    "    fig.suptitle(f\"Results for eta = {eta_list[i]}\")\n",
    "    plt.subplot(2, 2, 1)\n",
    "    color= ['red' if elem>0.5 else 'blue' for elem in y_train ]\n",
    "    plt.scatter(X_train[:,-2], X_train[:,-1], c=color,label='the data')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title('Training dataset')\n",
    "\n",
    "    plt.subplot(2, 2, 2)\n",
    "    color= ['red' if elem>0.5 else 'blue' for elem in pred_train[i] ]\n",
    "    plt.scatter(X_train[:,-2], X_train[:,-1], c=color,label='the data')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title('Training dataset - predictions')\n",
    "\n",
    "    plt.subplot(2, 2, 3)\n",
    "    color= ['red' if elem>0.5 else 'blue' for elem in y_test ]\n",
    "    plt.scatter(X_test[:,-2], X_test[:,-1], c=color,label='the data')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title('Test dataset')\n",
    "\n",
    "    plt.subplot(2, 2, 4)\n",
    "    color= ['red' if elem>0.5 else 'blue' for elem in pred_test[i] ]\n",
    "    plt.scatter(X_test[:,-2], X_test[:,-1], c=color,label='the data')\n",
    "    plt.xlabel('x1')\n",
    "    plt.ylabel('x2')\n",
    "    plt.title('Test dataset - predictions')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "In the following cell the data set `DataSet_LR_a.csv` is loaded and split into a training set and a test set ($50\\,\\%$ each). Now you should:\n",
    "* Classify samples as class `1` if the Logistic Regression returns values $\\geq 0.5$ and `0` otherwise. Calculate  the entries for a confusion matrix and from these values the Accuracy and Balanced Accuracy in the function `calc_acc(prediction, true_values, threshold)` and apply it on the training and on the test sets.\n",
    "* Provide ROC curves of the classifiers on the test samples and compute the corresponding AUC. Hint: the functions `roc_curve` and `auc` from `sklearn.metrics` might be useful. Make sure to store the calculated value for the AUC in the variable `rocAUC` - this is important for the unit-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "text"
    ]
   },
   "source": [
    "<h3 style=\"color:rgb(208,90,80)\">Code 1.8 (15 points)</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "code1.8"
    ]
   },
   "outputs": [],
   "source": [
    "def calc_acc(prediction:np.ndarray, true_values:np.ndarray, threshold = 0.5)-> Tuple[float,float,float,float,float,float,float,float]:\n",
    "    \"\"\"Function that makes predictions (0 or 1), according to the output of your logistic regression function and the given treshold, \n",
    "    and then calculates the accuracy, as well as the balanced accuracy of the predictions vs. true labels.\n",
    "    Again, only us numpy for this task.\n",
    "    Parameters\n",
    "    ----------\n",
    "    prediction : np.ndarray\n",
    "        label predictions\n",
    "    true_values : np.ndarray\n",
    "        true labels\n",
    "    threshold : float, optional\n",
    "        threshold for label decision, by default 0.5\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[float,float,float,float,float,float,float,float]\n",
    "        Returns the following, in percentages between 0 and 1:\n",
    "                pos, float, positive samples \n",
    "                neg, float, negative samples \n",
    "                tp, float, true positive samples \n",
    "                tn, float, true negative samples \n",
    "                fp, float, false positive samples \n",
    "                fn, float, false negative samples \n",
    "                acc, float, accuracy\n",
    "                balanced_acc, float, balanced accuracy\n",
    "    \"\"\"    \n",
    "    pos = None\n",
    "    neg = None\n",
    "    tp = None \n",
    "    tn = None \n",
    "    fp = None \n",
    "    fn = None \n",
    "    acc = None \n",
    "    balanced_acc = None \n",
    "    \n",
    "    # your code go here ↓↓↓\n",
    "    \n",
    "    return pos, neg, tp, tn, fp, fn, acc, balanced_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exec"
    ]
   },
   "outputs": [],
   "source": [
    "# Calculate accuracy and balanced accuracy for test set\n",
    "\n",
    "w_learned,losses=fitLogRegModel(X_train, y_train,cost,logistic_gradient,eta=1e-4)\n",
    "pred_train = predictLogReg(w_learned, X_train)\n",
    "pred_test = predictLogReg(w_learned, X_test)\n",
    "\n",
    "result_train = calc_acc(pred_train, y_train)\n",
    "result_test = calc_acc(pred_test, y_test)\n",
    "print(\"\\nAccuracy on training data:\", result_train[-2])\n",
    "print(\"Balanced accuracy on training data:\",result_train[-1])\n",
    "print(\"Accuracy on test data:\",result_test[-2])\n",
    "print(\"Balanced accuracy on test data:\",result_test[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"color:rgb(208,90,80)\">Code 1.9 (15 points)</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "code1.9"
    ]
   },
   "outputs": [],
   "source": [
    "## Solution begin\n",
    "def roc_auc(y_test:np.ndarray,y_pred:np.ndarray)-> Tuple[plt.figure,float]:\n",
    "    \"\"\"Function that calculates the ROC and returns the corresponding AUC of the input predictions vs the true labels,\n",
    "    as a value and also plots the ROC curve and returns the figure.\n",
    "    You are only allowed to use the imported sklearn functions.\n",
    "    Hint: Make sure to return the correct figure (don't use plt.fig() again in your code, or plt.subplots())\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_test : np.ndarray\n",
    "        True labels of test data\n",
    "    y_pred : np.ndarray\n",
    "        Predictions of test labels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[plt.figure,float]\n",
    "        figure: matplotlib figure, containing the plot of the ROC curve\n",
    "        rocAUC: float, value for the area under the computed ROC curve\n",
    "    \"\"\"\n",
    "    fig = plt.figure()\n",
    "    rocAUC = None\n",
    "    \n",
    "    # your code go here ↓↓↓\n",
    "\n",
    "    return fig, rocAUC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, roc_AUC = roc_auc(y_test,pred_test)\n",
    "assert type(fig) == matplotlib.figure.Figure, \"Function does not return Figure.\"\n",
    "print(\"Computed AUC =\",roc_AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "exec_check"
    ]
   },
   "outputs": [],
   "source": [
    "# Implementation check:\n",
    "## Executability does not guarantee correctness of your solutions!\n",
    "X = np.asarray([[0,1],[1,0]])\n",
    "y = np.asarray([0,1])\n",
    "w = np.asarray([1,1])\n",
    "analytical_gradient = logistic_gradient(w,X,y)\n",
    "num_gradient = numerical_gradient(w,X,y,[1e-4],cost)\n",
    "comparison(analytical_gradient, num_gradient)\n",
    "fitLogRegModel(X, y,cost,logistic_gradient,eta=0.0)\n",
    "predictLogReg(w,X)\n",
    "for i,a in enumerate([eps_0_,eps_1_,eps_2_,a15_,b15_,c15_,d15_ ,e15_,f15_, a17_,b17_,c17_,d17_,e17_]):\n",
    "    assert a is not None, (f\"Question(s) not answered! ({i}th in list)\")\n",
    "calc_acc(y,np.asarray([1,0]),0.5)\n",
    "roc_auc(y,np.asarray([1,1]))\n",
    "print(\"Executable\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
